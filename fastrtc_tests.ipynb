{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_size = \"distil-large-v2\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "stt_tokenizer = AutoTokenizer.from_pretrained(\"distil-whisper/distil-large-v2\")\n",
    "\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "\n",
    "def capture_audio_continuous(sample_rate=16000, chunk_size=1024, channels=1):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=channels,\n",
    "                    rate=sample_rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk_size)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(chunk_size)\n",
    "            yield np.frombuffer(data, dtype=np.int16)\n",
    "    finally:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "def longest_common_prefix(str1, str2):\n",
    "    # Find the minimum length of the two strings\n",
    "    min_length = min(len(str1), len(str2))\n",
    "    \n",
    "    # Iterate through characters up to the minimum length\n",
    "    for i in range(min_length):\n",
    "        # If we find a mismatch, return the prefix up to this point\n",
    "        if str1[i] != str2[i]:\n",
    "            return str1[:i]\n",
    "    \n",
    "    # If we reached the end of the loop without finding a mismatch,\n",
    "    # the entire shorter string is a prefix of the longer one\n",
    "    return str1[:min_length]\n",
    "\n",
    "def longest_common_prefix_word_level(word_list_1, word_list_2):\n",
    "    # Find the minimum length of the two strings\n",
    "    min_length = min(len(word_list_1), len(word_list_2))\n",
    "    \n",
    "    # Iterate through characters up to the minimum length\n",
    "    for i in range(min_length):\n",
    "        # If we find a mismatch, return the prefix up to this point\n",
    "        if word_list_1[i].word != word_list_2[i].word:\n",
    "            if len(word_list_1[:i]) > 0:\n",
    "                return word_list_1[:i], word_list_1[:i][0].start, word_list_1[i].start\n",
    "            else:\n",
    "                return [], None, None\n",
    "    \n",
    "    # If we reached the end of the loop without finding a mismatch,\n",
    "    # the entire shorter string is a prefix of the longer one\n",
    "    lcp = word_list_1[:min_length]\n",
    "    return lcp, lcp[0].start, lcp[-1].end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = \"\"\n",
    "previous_txt_seg = []\n",
    "for segment in segments_list:\n",
    "    if previous_txt_seg != []:\n",
    "        confirmed_txt_seg, start, end = longest_common_prefix_word_level(previous_txt_seg, segment)\n",
    "        final_text += \"\".join([i.word for i in confirmed_txt_seg])\n",
    "        previous_txt_seg = segment[len(confirmed_txt_seg):]\n",
    "    else:\n",
    "        previous_txt_seg = segment\n",
    "    print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2721:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "Cannot connect to server socket err = No such file or directory\n",
      "Cannot connect to server request channel\n",
      "jack server is not running or cannot be started\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
      "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "previous_segment: \n",
      "current_segment:  Thank you\n",
      "final_text: \n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  Thank you\n",
      "current_segment:  When the world war broke out he joined the way.\n",
      "segment_overlap: \n",
      "final_text: \n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  When the world war broke out he joined the way.\n",
      "current_segment:  When World War II broke out, he joined the Royal Navy, finishing it.\n",
      "segment_overlap:  When\n",
      "final_text:  When\n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  World War II broke out, he joined the Royal Navy, finishing it.\n",
      "current_segment:  The World War broke up, he joined the Royal Navy, finishing his five-year stint as a lieutenant.\n",
      "segment_overlap: \n",
      "final_text:  When\n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  The World War broke up, he joined the Royal Navy, finishing his five-year stint as a lieutenant.\n",
      "current_segment:  The World War broke up. He joined the Royal Navy, finishing his five years stint as a lieutenant in the rocket vessel.\n",
      "segment_overlap:  The World War broke\n",
      "final_text:  When The World War broke\n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  up. He joined the Royal Navy, finishing his five years stint as a lieutenant in the rocket vessel.\n",
      "current_segment:  He joined the Royal Navy, finishing his five-year stint as a lieutenant in the rocket vessel. He has seen combat duty against.\n",
      "segment_overlap: \n",
      "final_text:  When The World War broke\n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  He joined the Royal Navy, finishing his five-year stint as a lieutenant in the rocket vessel. He has seen combat duty against.\n",
      "current_segment:  He joined the Royal Navy, finishing his five-year stint as a lieutenant in the rocket vessel. He has seen combat duty against our ships, submarines and air.\n",
      "segment_overlap:  He joined the Royal Navy, finishing his five-year stint as a lieutenant in the rocket vessel. He has seen combat duty\n",
      "final_text:  When The World War broke He joined the Royal Navy, finishing his five-year stint as a lieutenant in the rocket vessel. He has seen combat duty\n",
      "--------------------\n",
      "--------------------\n",
      "previous_segment:  against our ships, submarines and air.\n",
      "current_segment:  to ship submarines and aircraft.\n",
      "segment_overlap: \n",
      "final_text:  When The World War broke He joined the Royal Navy, finishing his five-year stint as a lieutenant in the rocket vessel. He has seen combat duty\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m previous_txt_seg = []\n\u001b[32m     15\u001b[39m transcribed_bits = []\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maudio_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcapture_audio_continuous\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcurr_window_chunk_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_chunks\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollected_chunks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mcapture_audio_continuous\u001b[39m\u001b[34m(sample_rate, chunk_size, channels)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m         data = \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m np.frombuffer(data, dtype=np.int16)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/small_utils/.venv/lib/python3.12/site-packages/pyaudio/__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def get_text_segment(words):\n",
    "    return \"\".join([i.word for i in words])\n",
    "\n",
    "sample_rate = 16000\n",
    "chunk_size = 1024\n",
    "chunk_duration = chunk_size / sample_rate\n",
    "sec_duration_to_capture = 2\n",
    "\n",
    "total_chunks = int(sec_duration_to_capture * sample_rate / chunk_size)\n",
    "collected_chunks = []\n",
    "curr_window_chunk_count = 0\n",
    "\n",
    "final_text = \"\"\n",
    "previous_txt_seg = []\n",
    "transcribed_bits = []\n",
    "for audio_output in capture_audio_continuous(sample_rate, chunk_size):\n",
    "        \n",
    "    if curr_window_chunk_count < total_chunks:\n",
    "        collected_chunks.append(audio_output)\n",
    "        curr_window_chunk_count += 1\n",
    "    \n",
    "    elif curr_window_chunk_count == total_chunks:\n",
    "        audio_snippet = np.concatenate(collected_chunks)\n",
    "        segments, info = model.transcribe(audio_snippet, initial_prompt=final_text, word_timestamps=True, language=\"en\")\n",
    "        segs = [i for i in segments]\n",
    "        transcribed_bits.append(segs)\n",
    "        \n",
    "        curr_chunk_words = []\n",
    "        for seg in segs:\n",
    "            curr_chunk_words.extend(seg.words)\n",
    "        print(\"--\"*10)\n",
    "        print(\"previous_segment:\", get_text_segment(previous_txt_seg))\n",
    "        print(\"current_segment:\", get_text_segment(curr_chunk_words))\n",
    "        if previous_txt_seg != []:\n",
    "            confirmed_txt_seg, st, end = longest_common_prefix_word_level(previous_txt_seg, curr_chunk_words)\n",
    "            print(\"segment_overlap:\", get_text_segment(confirmed_txt_seg))           \n",
    "            if confirmed_txt_seg != []:\n",
    "                final_text += get_text_segment(confirmed_txt_seg)\n",
    "                previous_txt_seg = curr_chunk_words[len(confirmed_txt_seg):]\n",
    "                \n",
    "                num_chunks_to_remove = int(end / chunk_duration)\n",
    "                collected_chunks = collected_chunks[num_chunks_to_remove:]\n",
    "            else:\n",
    "                previous_txt_seg = curr_chunk_words\n",
    "        else:\n",
    "            previous_txt_seg = curr_chunk_words\n",
    "\n",
    "        curr_window_chunk_count = 0\n",
    "    \n",
    "        print(\"final_text:\", final_text)\n",
    "        print(\"--\"*10) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"When World War II broke He joined the Royal Navy finishing He has five-year stint as a You tend in command of a rocket vessel. He has seen battleships, submarines and aircraft and participated in He earned the reputation of men when they notice that in moments His facial muscles would contract Bye-bye!\"\n",
    "\n",
    "\"When War II broke up, he tried to We may be finishing his five-year stint as a a attendant in command of the rocket vessel. He has seen any combat duty against battleships, submarines, and aircraft. participated in the eBay operations. He earned among his men when they Notice that in moments of stress during combat, his facial muscles would contract violently causing a broad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159744"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_1 = np.concatenate(chunks_lists[0])\n",
    "print(len(chunk_1))\n",
    "chunk_2 = np.concatenate(chunks_lists[1])\n",
    "len(chunk_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Segment(id=1, seek=0, start=np.float64(0.0), end=np.float64(4.52), text=' William Golding was born in Cornwall, England in 1911.', tokens=[50364, 6740, 6731, 278, 390, 4232, 294, 21590, 16256, 11, 8196, 294, 1294, 5348, 13, 50614], avg_logprob=-0.19025735294117646, compression_ratio=0.9310344827586207, no_speech_prob=0.034027099609375, words=[Word(start=np.float64(0.0), end=np.float64(0.94), word=' William', probability=np.float64(0.71533203125)), Word(start=np.float64(0.94), end=np.float64(1.56), word=' Golding', probability=np.float64(0.53564453125)), Word(start=np.float64(1.56), end=np.float64(1.8), word=' was', probability=np.float64(0.96484375)), Word(start=np.float64(1.8), end=np.float64(2.06), word=' born', probability=np.float64(0.8974609375)), Word(start=np.float64(2.06), end=np.float64(2.3), word=' in', probability=np.float64(0.9326171875)), Word(start=np.float64(2.3), end=np.float64(2.96), word=' Cornwall,', probability=np.float64(0.742431640625)), Word(start=np.float64(2.96), end=np.float64(3.34), word=' England', probability=np.float64(0.9375)), Word(start=np.float64(3.34), end=np.float64(3.8), word=' in', probability=np.float64(0.75732421875)), Word(start=np.float64(3.8), end=np.float64(4.52), word=' 1911.', probability=np.float64(0.96826171875))], temperature=0.0)],\n",
       " [Segment(id=1, seek=0, start=np.float64(0.0), end=np.float64(7.2), text=' William Golding was born in Cornwall, England in 1911 and is a graduate of Oxford University.', tokens=[50364, 6740, 6731, 278, 390, 4232, 294, 21590, 16256, 11, 8196, 294, 1294, 5348, 293, 307, 257, 8080, 295, 24786, 3535, 13, 50714], avg_logprob=-0.1386718712747097, compression_ratio=1.1900826446280992, no_speech_prob=0.056243896484375, words=[Word(start=np.float64(0.0), end=np.float64(0.92), word=' William', probability=np.float64(0.74267578125)), Word(start=np.float64(0.92), end=np.float64(1.54), word=' Golding', probability=np.float64(0.76611328125)), Word(start=np.float64(1.54), end=np.float64(1.8), word=' was', probability=np.float64(0.96337890625)), Word(start=np.float64(1.8), end=np.float64(2.04), word=' born', probability=np.float64(0.9140625)), Word(start=np.float64(2.04), end=np.float64(2.3), word=' in', probability=np.float64(0.96484375)), Word(start=np.float64(2.3), end=np.float64(2.9), word=' Cornwall,', probability=np.float64(0.937255859375)), Word(start=np.float64(3.06), end=np.float64(3.38), word=' England', probability=np.float64(0.7861328125)), Word(start=np.float64(3.38), end=np.float64(3.8), word=' in', probability=np.float64(0.62255859375)), Word(start=np.float64(3.8), end=np.float64(4.54), word=' 1911', probability=np.float64(0.96240234375)), Word(start=np.float64(4.54), end=np.float64(5.2), word=' and', probability=np.float64(0.884765625)), Word(start=np.float64(5.2), end=np.float64(5.34), word=' is', probability=np.float64(0.92333984375)), Word(start=np.float64(5.34), end=np.float64(5.48), word=' a', probability=np.float64(0.98876953125)), Word(start=np.float64(5.48), end=np.float64(5.86), word=' graduate', probability=np.float64(0.90087890625)), Word(start=np.float64(5.86), end=np.float64(6.1), word=' of', probability=np.float64(0.943359375)), Word(start=np.float64(6.1), end=np.float64(6.58), word=' Oxford', probability=np.float64(0.9501953125)), Word(start=np.float64(6.58), end=np.float64(7.2), word=' University.', probability=np.float64(0.8857421875))], temperature=0.0),\n",
       "  Segment(id=2, seek=0, start=np.float64(7.5), end=np.float64(9.96), text=' He states that he was brought up to be assigned to', tokens=[50714, 634, 4368, 220, 6780, 415, 390, 3038, 493, 220, 1353, 312, 13279, 220, 1353, 50864], avg_logprob=-0.1386718712747097, compression_ratio=1.1900826446280992, no_speech_prob=0.056243896484375, words=[Word(start=np.float64(7.5), end=np.float64(7.82), word=' He', probability=np.float64(0.9482421875)), Word(start=np.float64(7.82), end=np.float64(8.2), word=' states', probability=np.float64(0.92333984375)), Word(start=np.float64(8.2), end=np.float64(8.46), word=' that', probability=np.float64(0.812744140625)), Word(start=np.float64(8.46), end=np.float64(8.66), word=' he', probability=np.float64(0.95849609375)), Word(start=np.float64(8.66), end=np.float64(8.8), word=' was', probability=np.float64(0.955078125)), Word(start=np.float64(8.8), end=np.float64(9.1), word=' brought', probability=np.float64(0.97412109375)), Word(start=np.float64(9.1), end=np.float64(9.3), word=' up', probability=np.float64(0.91845703125)), Word(start=np.float64(9.3), end=np.float64(9.32), word=' to', probability=np.float64(0.85791015625)), Word(start=np.float64(9.32), end=np.float64(9.5), word=' be', probability=np.float64(0.95068359375)), Word(start=np.float64(9.5), end=np.float64(9.86), word=' assigned', probability=np.float64(0.90185546875)), Word(start=np.float64(9.86), end=np.float64(9.96), word=' to', probability=np.float64(0.72265625))], temperature=0.0)],\n",
       " [Segment(id=1, seek=0, start=np.float64(0.0), end=np.float64(4.98), text=' and is a graduate of Oxford University. He states that he was brought up to be a scientist', tokens=[50364, 293, 307, 257, 8080, 295, 24786, 3535, 13, 634, 4368, 220, 6780, 415, 390, 3038, 493, 220, 1353, 312, 257, 12662, 50620], avg_logprob=-0.188833838555871, compression_ratio=1.3220338983050848, no_speech_prob=0.0675048828125, words=[Word(start=np.float64(0.0), end=np.float64(0.22), word=' and', probability=np.float64(0.943359375)), Word(start=np.float64(0.22), end=np.float64(0.36), word=' is', probability=np.float64(0.607421875)), Word(start=np.float64(0.36), end=np.float64(0.48), word=' a', probability=np.float64(0.98486328125)), Word(start=np.float64(0.48), end=np.float64(0.88), word=' graduate', probability=np.float64(0.90380859375)), Word(start=np.float64(0.88), end=np.float64(1.14), word=' of', probability=np.float64(0.9462890625)), Word(start=np.float64(1.14), end=np.float64(1.58), word=' Oxford', probability=np.float64(0.96533203125)), Word(start=np.float64(1.58), end=np.float64(2.18), word=' University.', probability=np.float64(0.88623046875)), Word(start=np.float64(2.36), end=np.float64(2.82), word=' He', probability=np.float64(0.93310546875)), Word(start=np.float64(2.82), end=np.float64(3.2), word=' states', probability=np.float64(0.93701171875)), Word(start=np.float64(3.2), end=np.float64(3.44), word=' that', probability=np.float64(0.81982421875)), Word(start=np.float64(3.44), end=np.float64(3.66), word=' he', probability=np.float64(0.9521484375)), Word(start=np.float64(3.66), end=np.float64(3.8), word=' was', probability=np.float64(0.94873046875)), Word(start=np.float64(3.8), end=np.float64(4.08), word=' brought', probability=np.float64(0.97265625)), Word(start=np.float64(4.08), end=np.float64(4.3), word=' up', probability=np.float64(0.92626953125)), Word(start=np.float64(4.3), end=np.float64(4.36), word=' to', probability=np.float64(0.871826171875)), Word(start=np.float64(4.36), end=np.float64(4.52), word=' be', probability=np.float64(0.95849609375)), Word(start=np.float64(4.52), end=np.float64(4.64), word=' a', probability=np.float64(0.489501953125)), Word(start=np.float64(4.64), end=np.float64(4.98), word=' scientist', probability=np.float64(0.87646484375))], temperature=0.0),\n",
       "  Segment(id=2, seek=0, start=np.float64(4.98), end=np.float64(9.96), text=' or rebelled and after three years of Oxford changed his plans and', tokens=[50620, 420, 319, 650, 5929, 293, 934, 220, 27583, 924, 295, 24786, 3105, 702, 5482, 293, 50872], avg_logprob=-0.188833838555871, compression_ratio=1.3220338983050848, no_speech_prob=0.0675048828125, words=[Word(start=np.float64(4.98), end=np.float64(5.3), word=' or', probability=np.float64(0.86181640625)), Word(start=np.float64(5.3), end=np.float64(5.76), word=' rebelled', probability=np.float64(0.8857421875)), Word(start=np.float64(5.76), end=np.float64(6.28), word=' and', probability=np.float64(0.7880859375)), Word(start=np.float64(6.28), end=np.float64(6.6), word=' after', probability=np.float64(0.875)), Word(start=np.float64(6.6), end=np.float64(7.0), word=' three', probability=np.float64(0.789306640625)), Word(start=np.float64(7.0), end=np.float64(7.44), word=' years', probability=np.float64(0.92724609375)), Word(start=np.float64(7.44), end=np.float64(7.66), word=' of', probability=np.float64(0.9453125)), Word(start=np.float64(7.66), end=np.float64(8.24), word=' Oxford', probability=np.float64(0.96923828125)), Word(start=np.float64(8.24), end=np.float64(9.22), word=' changed', probability=np.float64(0.444580078125)), Word(start=np.float64(9.22), end=np.float64(9.44), word=' his', probability=np.float64(0.94775390625)), Word(start=np.float64(9.44), end=np.float64(9.78), word=' plans', probability=np.float64(0.90234375)), Word(start=np.float64(9.78), end=np.float64(9.96), word=' and', probability=np.float64(0.63671875))], temperature=0.0)],\n",
       " [Segment(id=1, seek=0, start=np.float64(0.0), end=np.float64(6.82), text=' a rebel and after three years of Oxford changed his plans and devoted himself to English literature.', tokens=[50364, 257, 28293, 293, 934, 220, 27583, 924, 295, 24786, 3105, 702, 5482, 293, 21815, 3647, 220, 1353, 3669, 10394, 13, 50714], avg_logprob=-0.19366776198148727, compression_ratio=1.226890756302521, no_speech_prob=0.119873046875, words=[Word(start=np.float64(0.0), end=np.float64(0.24), word=' a', probability=np.float64(0.6787109375)), Word(start=np.float64(0.24), end=np.float64(0.72), word=' rebel', probability=np.float64(0.796875)), Word(start=np.float64(0.72), end=np.float64(1.3), word=' and', probability=np.float64(0.94677734375)), Word(start=np.float64(1.3), end=np.float64(1.6), word=' after', probability=np.float64(0.943359375)), Word(start=np.float64(1.6), end=np.float64(2.0), word=' three', probability=np.float64(0.814208984375)), Word(start=np.float64(2.0), end=np.float64(2.46), word=' years', probability=np.float64(0.93505859375)), Word(start=np.float64(2.46), end=np.float64(2.68), word=' of', probability=np.float64(0.81201171875)), Word(start=np.float64(2.68), end=np.float64(3.22), word=' Oxford', probability=np.float64(0.86962890625)), Word(start=np.float64(3.22), end=np.float64(4.24), word=' changed', probability=np.float64(0.88818359375)), Word(start=np.float64(4.24), end=np.float64(4.44), word=' his', probability=np.float64(0.94482421875)), Word(start=np.float64(4.44), end=np.float64(4.8), word=' plans', probability=np.float64(0.931640625)), Word(start=np.float64(4.8), end=np.float64(4.98), word=' and', probability=np.float64(0.9501953125)), Word(start=np.float64(4.98), end=np.float64(5.24), word=' devoted', probability=np.float64(0.9287109375)), Word(start=np.float64(5.24), end=np.float64(5.7), word=' himself', probability=np.float64(0.95458984375)), Word(start=np.float64(5.7), end=np.float64(6.0), word=' to', probability=np.float64(0.890625)), Word(start=np.float64(6.0), end=np.float64(6.3), word=' English', probability=np.float64(0.9423828125)), Word(start=np.float64(6.3), end=np.float64(6.82), word=' literature.', probability=np.float64(0.91943359375))], temperature=0.0),\n",
       "  Segment(id=2, seek=0, start=np.float64(7.24), end=np.float64(9.96), text=\" When World War II broke out, he didn't do it.\", tokens=[50714, 1133, 3937, 3630, 6351, 6902, 484, 11, 415, 994, 380, 360, 309, 13, 50864], avg_logprob=-0.19366776198148727, compression_ratio=1.226890756302521, no_speech_prob=0.119873046875, words=[Word(start=np.float64(7.24), end=np.float64(7.56), word=' When', probability=np.float64(0.91259765625)), Word(start=np.float64(7.56), end=np.float64(7.86), word=' World', probability=np.float64(0.85205078125)), Word(start=np.float64(7.86), end=np.float64(8.08), word=' War', probability=np.float64(0.95849609375)), Word(start=np.float64(8.08), end=np.float64(8.36), word=' II', probability=np.float64(0.83056640625)), Word(start=np.float64(8.36), end=np.float64(8.7), word=' broke', probability=np.float64(0.91796875)), Word(start=np.float64(8.7), end=np.float64(9.14), word=' out,', probability=np.float64(0.89794921875)), Word(start=np.float64(9.42), end=np.float64(9.58), word=' he', probability=np.float64(0.96923828125)), Word(start=np.float64(9.58), end=np.float64(9.86), word=\" didn't\", probability=np.float64(0.9638671875)), Word(start=np.float64(9.86), end=np.float64(9.96), word=' do', probability=np.float64(0.96435546875)), Word(start=np.float64(9.96), end=np.float64(9.96), word=' it.', probability=np.float64(0.17724609375))], temperature=0.0)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribed_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " William Golding was born in Cornwall, England in 1911.\n",
      "----------------------------------------\n",
      " William Golding was born in Cornwall, England in 1911 and is a graduate of Oxford University.  He states that he was brought up to be assigned to\n",
      "----------------------------------------\n",
      " and is a graduate of Oxford University. He states that he was brought up to be a scientist  or rebelled and after three years of Oxford changed his plans and\n",
      "----------------------------------------\n",
      " a rebel and after three years of Oxford changed his plans and devoted himself to English literature.  When World War II broke out, he didn't do it.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text_segs = []\n",
    "for seg in transcribed_bits:\n",
    "    x = \" \".join([i.text for i in seg])\n",
    "    text_segs.append(x)\n",
    "    print(x)\n",
    "    print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_words = []\n",
    "for seg in transcribed_bits:\n",
    "    chunk_words = []\n",
    "    for s in seg:\n",
    "        seg_words.append(s.words)\n",
    "        chunk_words.extend(s.words)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word(start=np.float64(0.0), end=np.float64(0.52), word=' Hello,', probability=np.float64(0.9091796875)),\n",
       " Word(start=np.float64(1.18), end=np.float64(1.4), word=\" I'm\", probability=np.float64(0.836181640625)),\n",
       " Word(start=np.float64(1.4), end=np.float64(1.76), word=' doing', probability=np.float64(0.96337890625)),\n",
       " Word(start=np.float64(1.76), end=np.float64(2.18), word=' good.', probability=np.float64(0.92822265625)),\n",
       " Word(start=np.float64(2.38), end=np.float64(2.6), word=' My', probability=np.float64(0.9775390625)),\n",
       " Word(start=np.float64(2.6), end=np.float64(2.76), word=' name', probability=np.float64(0.9150390625)),\n",
       " Word(start=np.float64(2.76), end=np.float64(2.92), word=' is', probability=np.float64(0.9560546875)),\n",
       " Word(start=np.float64(2.92), end=np.float64(3.3), word=' William', probability=np.float64(0.900390625)),\n",
       " Word(start=np.float64(3.3), end=np.float64(4.02), word=' Colding', probability=np.float64(0.6488037109375)),\n",
       " Word(start=np.float64(4.02), end=np.float64(4.42), word=' of', probability=np.float64(0.96484375)),\n",
       " Word(start=np.float64(4.42), end=np.float64(4.84), word=' England.', probability=np.float64(0.94091796875))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_prefix_word_level(word_list_1, word_list_2):\n",
    "    # Find the minimum length of the two strings\n",
    "    min_length = min(len(word_list_1), len(word_list_2))\n",
    "    \n",
    "    # Iterate through characters up to the minimum length\n",
    "    for i in range(min_length):\n",
    "        # If we find a mismatch, return the prefix up to this point\n",
    "        if word_list_1[i].word != word_list_2[i].word:\n",
    "            return word_list_1[:i], word_list_1[:i][0].start, word_list_1[:i][-1].end\n",
    "    \n",
    "    # If we reached the end of the loop without finding a mismatch,\n",
    "    # the entire shorter string is a prefix of the longer one\n",
    "    lcp = word_list_1[:min_length]\n",
    "    return lcp, lcp[0].start. lcp[-1].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Word(start=np.float64(0.0), end=np.float64(0.94), word=' William', probability=np.float64(0.71533203125)), Word(start=np.float64(0.94), end=np.float64(1.56), word=' Golding', probability=np.float64(0.53564453125)), Word(start=np.float64(1.56), end=np.float64(1.8), word=' was', probability=np.float64(0.96484375)), Word(start=np.float64(1.8), end=np.float64(2.06), word=' born', probability=np.float64(0.8974609375)), Word(start=np.float64(2.06), end=np.float64(2.3), word=' in', probability=np.float64(0.9326171875)), Word(start=np.float64(2.3), end=np.float64(2.96), word=' Cornwall,', probability=np.float64(0.742431640625)), Word(start=np.float64(2.96), end=np.float64(3.34), word=' England', probability=np.float64(0.9375)), Word(start=np.float64(3.34), end=np.float64(3.8), word=' in', probability=np.float64(0.75732421875)), Word(start=np.float64(3.8), end=np.float64(4.52), word=' 1911.', probability=np.float64(0.96826171875))]\n",
      " William Golding was born in Cornwall, England in 1911.\n",
      "[Word(start=np.float64(0.0), end=np.float64(0.92), word=' William', probability=np.float64(0.74267578125)), Word(start=np.float64(0.92), end=np.float64(1.54), word=' Golding', probability=np.float64(0.76611328125)), Word(start=np.float64(1.54), end=np.float64(1.8), word=' was', probability=np.float64(0.96337890625)), Word(start=np.float64(1.8), end=np.float64(2.04), word=' born', probability=np.float64(0.9140625)), Word(start=np.float64(2.04), end=np.float64(2.3), word=' in', probability=np.float64(0.96484375)), Word(start=np.float64(2.3), end=np.float64(2.9), word=' Cornwall,', probability=np.float64(0.937255859375)), Word(start=np.float64(3.06), end=np.float64(3.38), word=' England', probability=np.float64(0.7861328125)), Word(start=np.float64(3.38), end=np.float64(3.8), word=' in', probability=np.float64(0.62255859375)), Word(start=np.float64(3.8), end=np.float64(4.54), word=' 1911', probability=np.float64(0.96240234375)), Word(start=np.float64(4.54), end=np.float64(5.2), word=' and', probability=np.float64(0.884765625)), Word(start=np.float64(5.2), end=np.float64(5.34), word=' is', probability=np.float64(0.92333984375)), Word(start=np.float64(5.34), end=np.float64(5.48), word=' a', probability=np.float64(0.98876953125)), Word(start=np.float64(5.48), end=np.float64(5.86), word=' graduate', probability=np.float64(0.90087890625)), Word(start=np.float64(5.86), end=np.float64(6.1), word=' of', probability=np.float64(0.943359375)), Word(start=np.float64(6.1), end=np.float64(6.58), word=' Oxford', probability=np.float64(0.9501953125)), Word(start=np.float64(6.58), end=np.float64(7.2), word=' University.', probability=np.float64(0.8857421875))]\n",
      " William Golding was born in Cornwall, England in 1911 and is a graduate of Oxford University.\n",
      "[Word(start=np.float64(0.0), end=np.float64(0.94), word=' William', probability=np.float64(0.71533203125)), Word(start=np.float64(0.94), end=np.float64(1.56), word=' Golding', probability=np.float64(0.53564453125)), Word(start=np.float64(1.56), end=np.float64(1.8), word=' was', probability=np.float64(0.96484375)), Word(start=np.float64(1.8), end=np.float64(2.06), word=' born', probability=np.float64(0.8974609375)), Word(start=np.float64(2.06), end=np.float64(2.3), word=' in', probability=np.float64(0.9326171875)), Word(start=np.float64(2.3), end=np.float64(2.96), word=' Cornwall,', probability=np.float64(0.742431640625)), Word(start=np.float64(2.96), end=np.float64(3.34), word=' England', probability=np.float64(0.9375)), Word(start=np.float64(3.34), end=np.float64(3.8), word=' in', probability=np.float64(0.75732421875))]\n",
      " William Golding was born in Cornwall, England in\n"
     ]
    }
   ],
   "source": [
    "print(seg_words[0])\n",
    "print(\"\".join([i.word for i in seg_words[0]]))\n",
    "print(seg_words[1])\n",
    "print(\"\".join([i.word for i in seg_words[1]]))\n",
    "com_pre = longest_common_prefix_word_level(seg_words[0], seg_words[1])\n",
    "print(com_pre)\n",
    "print(\"\".join([i.word for i in com_pre]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_list = []\n",
    "for seg in transcribed_bits:\n",
    "    for i in seg:\n",
    "        segments_list.append(i.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Word(start=np.float64(0.0), end=np.float64(0.94), word=' William', probability=np.float64(0.71533203125)),\n",
       " Word(start=np.float64(0.94), end=np.float64(1.56), word=' Golding', probability=np.float64(0.53564453125)),\n",
       " Word(start=np.float64(1.56), end=np.float64(1.8), word=' was', probability=np.float64(0.96484375)),\n",
       " Word(start=np.float64(1.8), end=np.float64(2.06), word=' born', probability=np.float64(0.8974609375)),\n",
       " Word(start=np.float64(2.06), end=np.float64(2.3), word=' in', probability=np.float64(0.9326171875)),\n",
       " Word(start=np.float64(2.3), end=np.float64(2.96), word=' Cornwall,', probability=np.float64(0.742431640625)),\n",
       " Word(start=np.float64(2.96), end=np.float64(3.34), word=' England', probability=np.float64(0.9375)),\n",
       " Word(start=np.float64(3.34), end=np.float64(3.8), word=' in', probability=np.float64(0.75732421875)),\n",
       " Word(start=np.float64(3.8), end=np.float64(4.52), word=' 1911.', probability=np.float64(0.96826171875))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " William Golding was born in Cornwall, England in\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m segment \u001b[38;5;129;01min\u001b[39;00m segments_list:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_txt_seg != []:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         confirmed_txt_seg, start, end = \u001b[43mlongest_common_prefix_word_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_txt_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m         final_text += \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([i.word \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m confirmed_txt_seg])\n\u001b[32m      7\u001b[39m         previous_txt_seg = segment[\u001b[38;5;28mlen\u001b[39m(confirmed_txt_seg):]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mlongest_common_prefix_word_level\u001b[39m\u001b[34m(word_list_1, word_list_2)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(min_length):\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# If we find a mismatch, return the prefix up to this point\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m word_list_1[i].word != word_list_2[i].word:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m word_list_1[:i], \u001b[43mword_list_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.start, word_list_1[:i][-\u001b[32m1\u001b[39m].end\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# If we reached the end of the loop without finding a mismatch,\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# the entire shorter string is a prefix of the longer one\u001b[39;00m\n\u001b[32m     13\u001b[39m lcp = word_list_1[:min_length]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "final_text = \"\"\n",
    "previous_txt_seg = []\n",
    "for segment in segments_list:\n",
    "    if previous_txt_seg != []:\n",
    "        confirmed_txt_seg, start, end = longest_common_prefix_word_level(previous_txt_seg, segment)\n",
    "        final_text += \"\".join([i.word for i in confirmed_txt_seg])\n",
    "        previous_txt_seg = segment[len(confirmed_txt_seg):]\n",
    "    else:\n",
    "        previous_txt_seg = segment\n",
    "    print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Word(start=np.float64(0.0), end=np.float64(0.94), word=' William', probability=np.float64(0.71533203125)), Word(start=np.float64(0.94), end=np.float64(1.56), word=' Golding', probability=np.float64(0.53564453125)), Word(start=np.float64(1.56), end=np.float64(1.8), word=' was', probability=np.float64(0.96484375)), Word(start=np.float64(1.8), end=np.float64(2.06), word=' born', probability=np.float64(0.8974609375)), Word(start=np.float64(2.06), end=np.float64(2.3), word=' in', probability=np.float64(0.9326171875)), Word(start=np.float64(2.3), end=np.float64(2.96), word=' Cornwall,', probability=np.float64(0.742431640625)), Word(start=np.float64(2.96), end=np.float64(3.34), word=' England', probability=np.float64(0.9375)), Word(start=np.float64(3.34), end=np.float64(3.8), word=' in', probability=np.float64(0.75732421875)), Word(start=np.float64(3.8), end=np.float64(4.52), word=' 1911.', probability=np.float64(0.96826171875))]]\n",
      "[[Word(start=np.float64(0.0), end=np.float64(0.92), word=' William', probability=np.float64(0.74267578125)), Word(start=np.float64(0.92), end=np.float64(1.54), word=' Golding', probability=np.float64(0.76611328125)), Word(start=np.float64(1.54), end=np.float64(1.8), word=' was', probability=np.float64(0.96337890625)), Word(start=np.float64(1.8), end=np.float64(2.04), word=' born', probability=np.float64(0.9140625)), Word(start=np.float64(2.04), end=np.float64(2.3), word=' in', probability=np.float64(0.96484375)), Word(start=np.float64(2.3), end=np.float64(2.9), word=' Cornwall,', probability=np.float64(0.937255859375)), Word(start=np.float64(3.06), end=np.float64(3.38), word=' England', probability=np.float64(0.7861328125)), Word(start=np.float64(3.38), end=np.float64(3.8), word=' in', probability=np.float64(0.62255859375)), Word(start=np.float64(3.8), end=np.float64(4.54), word=' 1911', probability=np.float64(0.96240234375)), Word(start=np.float64(4.54), end=np.float64(5.2), word=' and', probability=np.float64(0.884765625)), Word(start=np.float64(5.2), end=np.float64(5.34), word=' is', probability=np.float64(0.92333984375)), Word(start=np.float64(5.34), end=np.float64(5.48), word=' a', probability=np.float64(0.98876953125)), Word(start=np.float64(5.48), end=np.float64(5.86), word=' graduate', probability=np.float64(0.90087890625)), Word(start=np.float64(5.86), end=np.float64(6.1), word=' of', probability=np.float64(0.943359375)), Word(start=np.float64(6.1), end=np.float64(6.58), word=' Oxford', probability=np.float64(0.9501953125)), Word(start=np.float64(6.58), end=np.float64(7.2), word=' University.', probability=np.float64(0.8857421875))], [Word(start=np.float64(7.5), end=np.float64(7.82), word=' He', probability=np.float64(0.9482421875)), Word(start=np.float64(7.82), end=np.float64(8.2), word=' states', probability=np.float64(0.92333984375)), Word(start=np.float64(8.2), end=np.float64(8.46), word=' that', probability=np.float64(0.812744140625)), Word(start=np.float64(8.46), end=np.float64(8.66), word=' he', probability=np.float64(0.95849609375)), Word(start=np.float64(8.66), end=np.float64(8.8), word=' was', probability=np.float64(0.955078125)), Word(start=np.float64(8.8), end=np.float64(9.1), word=' brought', probability=np.float64(0.97412109375)), Word(start=np.float64(9.1), end=np.float64(9.3), word=' up', probability=np.float64(0.91845703125)), Word(start=np.float64(9.3), end=np.float64(9.32), word=' to', probability=np.float64(0.85791015625)), Word(start=np.float64(9.32), end=np.float64(9.5), word=' be', probability=np.float64(0.95068359375)), Word(start=np.float64(9.5), end=np.float64(9.86), word=' assigned', probability=np.float64(0.90185546875)), Word(start=np.float64(9.86), end=np.float64(9.96), word=' to', probability=np.float64(0.72265625))]]\n",
      "[[Word(start=np.float64(0.0), end=np.float64(0.22), word=' and', probability=np.float64(0.943359375)), Word(start=np.float64(0.22), end=np.float64(0.36), word=' is', probability=np.float64(0.607421875)), Word(start=np.float64(0.36), end=np.float64(0.48), word=' a', probability=np.float64(0.98486328125)), Word(start=np.float64(0.48), end=np.float64(0.88), word=' graduate', probability=np.float64(0.90380859375)), Word(start=np.float64(0.88), end=np.float64(1.14), word=' of', probability=np.float64(0.9462890625)), Word(start=np.float64(1.14), end=np.float64(1.58), word=' Oxford', probability=np.float64(0.96533203125)), Word(start=np.float64(1.58), end=np.float64(2.18), word=' University.', probability=np.float64(0.88623046875)), Word(start=np.float64(2.36), end=np.float64(2.82), word=' He', probability=np.float64(0.93310546875)), Word(start=np.float64(2.82), end=np.float64(3.2), word=' states', probability=np.float64(0.93701171875)), Word(start=np.float64(3.2), end=np.float64(3.44), word=' that', probability=np.float64(0.81982421875)), Word(start=np.float64(3.44), end=np.float64(3.66), word=' he', probability=np.float64(0.9521484375)), Word(start=np.float64(3.66), end=np.float64(3.8), word=' was', probability=np.float64(0.94873046875)), Word(start=np.float64(3.8), end=np.float64(4.08), word=' brought', probability=np.float64(0.97265625)), Word(start=np.float64(4.08), end=np.float64(4.3), word=' up', probability=np.float64(0.92626953125)), Word(start=np.float64(4.3), end=np.float64(4.36), word=' to', probability=np.float64(0.871826171875)), Word(start=np.float64(4.36), end=np.float64(4.52), word=' be', probability=np.float64(0.95849609375)), Word(start=np.float64(4.52), end=np.float64(4.64), word=' a', probability=np.float64(0.489501953125)), Word(start=np.float64(4.64), end=np.float64(4.98), word=' scientist', probability=np.float64(0.87646484375))], [Word(start=np.float64(4.98), end=np.float64(5.3), word=' or', probability=np.float64(0.86181640625)), Word(start=np.float64(5.3), end=np.float64(5.76), word=' rebelled', probability=np.float64(0.8857421875)), Word(start=np.float64(5.76), end=np.float64(6.28), word=' and', probability=np.float64(0.7880859375)), Word(start=np.float64(6.28), end=np.float64(6.6), word=' after', probability=np.float64(0.875)), Word(start=np.float64(6.6), end=np.float64(7.0), word=' three', probability=np.float64(0.789306640625)), Word(start=np.float64(7.0), end=np.float64(7.44), word=' years', probability=np.float64(0.92724609375)), Word(start=np.float64(7.44), end=np.float64(7.66), word=' of', probability=np.float64(0.9453125)), Word(start=np.float64(7.66), end=np.float64(8.24), word=' Oxford', probability=np.float64(0.96923828125)), Word(start=np.float64(8.24), end=np.float64(9.22), word=' changed', probability=np.float64(0.444580078125)), Word(start=np.float64(9.22), end=np.float64(9.44), word=' his', probability=np.float64(0.94775390625)), Word(start=np.float64(9.44), end=np.float64(9.78), word=' plans', probability=np.float64(0.90234375)), Word(start=np.float64(9.78), end=np.float64(9.96), word=' and', probability=np.float64(0.63671875))]]\n",
      "[[Word(start=np.float64(0.0), end=np.float64(0.24), word=' a', probability=np.float64(0.6787109375)), Word(start=np.float64(0.24), end=np.float64(0.72), word=' rebel', probability=np.float64(0.796875)), Word(start=np.float64(0.72), end=np.float64(1.3), word=' and', probability=np.float64(0.94677734375)), Word(start=np.float64(1.3), end=np.float64(1.6), word=' after', probability=np.float64(0.943359375)), Word(start=np.float64(1.6), end=np.float64(2.0), word=' three', probability=np.float64(0.814208984375)), Word(start=np.float64(2.0), end=np.float64(2.46), word=' years', probability=np.float64(0.93505859375)), Word(start=np.float64(2.46), end=np.float64(2.68), word=' of', probability=np.float64(0.81201171875)), Word(start=np.float64(2.68), end=np.float64(3.22), word=' Oxford', probability=np.float64(0.86962890625)), Word(start=np.float64(3.22), end=np.float64(4.24), word=' changed', probability=np.float64(0.88818359375)), Word(start=np.float64(4.24), end=np.float64(4.44), word=' his', probability=np.float64(0.94482421875)), Word(start=np.float64(4.44), end=np.float64(4.8), word=' plans', probability=np.float64(0.931640625)), Word(start=np.float64(4.8), end=np.float64(4.98), word=' and', probability=np.float64(0.9501953125)), Word(start=np.float64(4.98), end=np.float64(5.24), word=' devoted', probability=np.float64(0.9287109375)), Word(start=np.float64(5.24), end=np.float64(5.7), word=' himself', probability=np.float64(0.95458984375)), Word(start=np.float64(5.7), end=np.float64(6.0), word=' to', probability=np.float64(0.890625)), Word(start=np.float64(6.0), end=np.float64(6.3), word=' English', probability=np.float64(0.9423828125)), Word(start=np.float64(6.3), end=np.float64(6.82), word=' literature.', probability=np.float64(0.91943359375))], [Word(start=np.float64(7.24), end=np.float64(7.56), word=' When', probability=np.float64(0.91259765625)), Word(start=np.float64(7.56), end=np.float64(7.86), word=' World', probability=np.float64(0.85205078125)), Word(start=np.float64(7.86), end=np.float64(8.08), word=' War', probability=np.float64(0.95849609375)), Word(start=np.float64(8.08), end=np.float64(8.36), word=' II', probability=np.float64(0.83056640625)), Word(start=np.float64(8.36), end=np.float64(8.7), word=' broke', probability=np.float64(0.91796875)), Word(start=np.float64(8.7), end=np.float64(9.14), word=' out,', probability=np.float64(0.89794921875)), Word(start=np.float64(9.42), end=np.float64(9.58), word=' he', probability=np.float64(0.96923828125)), Word(start=np.float64(9.58), end=np.float64(9.86), word=\" didn't\", probability=np.float64(0.9638671875)), Word(start=np.float64(9.86), end=np.float64(9.96), word=' do', probability=np.float64(0.96435546875)), Word(start=np.float64(9.96), end=np.float64(9.96), word=' it.', probability=np.float64(0.17724609375))]]\n"
     ]
    }
   ],
   "source": [
    "for seg in transcribed_bits:\n",
    "    seg_words = [i.words for i in seg]\n",
    "    print(seg_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Word(start=np.float64(0.0), end=np.float64(0.24), word=' a', probability=np.float64(0.6787109375)),\n",
       "  Word(start=np.float64(0.24), end=np.float64(0.72), word=' rebel', probability=np.float64(0.796875)),\n",
       "  Word(start=np.float64(0.72), end=np.float64(1.3), word=' and', probability=np.float64(0.94677734375)),\n",
       "  Word(start=np.float64(1.3), end=np.float64(1.6), word=' after', probability=np.float64(0.943359375)),\n",
       "  Word(start=np.float64(1.6), end=np.float64(2.0), word=' three', probability=np.float64(0.814208984375)),\n",
       "  Word(start=np.float64(2.0), end=np.float64(2.46), word=' years', probability=np.float64(0.93505859375)),\n",
       "  Word(start=np.float64(2.46), end=np.float64(2.68), word=' of', probability=np.float64(0.81201171875)),\n",
       "  Word(start=np.float64(2.68), end=np.float64(3.22), word=' Oxford', probability=np.float64(0.86962890625)),\n",
       "  Word(start=np.float64(3.22), end=np.float64(4.24), word=' changed', probability=np.float64(0.88818359375)),\n",
       "  Word(start=np.float64(4.24), end=np.float64(4.44), word=' his', probability=np.float64(0.94482421875)),\n",
       "  Word(start=np.float64(4.44), end=np.float64(4.8), word=' plans', probability=np.float64(0.931640625)),\n",
       "  Word(start=np.float64(4.8), end=np.float64(4.98), word=' and', probability=np.float64(0.9501953125)),\n",
       "  Word(start=np.float64(4.98), end=np.float64(5.24), word=' devoted', probability=np.float64(0.9287109375)),\n",
       "  Word(start=np.float64(5.24), end=np.float64(5.7), word=' himself', probability=np.float64(0.95458984375)),\n",
       "  Word(start=np.float64(5.7), end=np.float64(6.0), word=' to', probability=np.float64(0.890625)),\n",
       "  Word(start=np.float64(6.0), end=np.float64(6.3), word=' English', probability=np.float64(0.9423828125)),\n",
       "  Word(start=np.float64(6.3), end=np.float64(6.82), word=' literature.', probability=np.float64(0.91943359375))],\n",
       " [Word(start=np.float64(7.24), end=np.float64(7.56), word=' When', probability=np.float64(0.91259765625)),\n",
       "  Word(start=np.float64(7.56), end=np.float64(7.86), word=' World', probability=np.float64(0.85205078125)),\n",
       "  Word(start=np.float64(7.86), end=np.float64(8.08), word=' War', probability=np.float64(0.95849609375)),\n",
       "  Word(start=np.float64(8.08), end=np.float64(8.36), word=' II', probability=np.float64(0.83056640625)),\n",
       "  Word(start=np.float64(8.36), end=np.float64(8.7), word=' broke', probability=np.float64(0.91796875)),\n",
       "  Word(start=np.float64(8.7), end=np.float64(9.14), word=' out,', probability=np.float64(0.89794921875)),\n",
       "  Word(start=np.float64(9.42), end=np.float64(9.58), word=' he', probability=np.float64(0.96923828125)),\n",
       "  Word(start=np.float64(9.58), end=np.float64(9.86), word=\" didn't\", probability=np.float64(0.9638671875)),\n",
       "  Word(start=np.float64(9.86), end=np.float64(9.96), word=' do', probability=np.float64(0.96435546875)),\n",
       "  Word(start=np.float64(9.96), end=np.float64(9.96), word=' it.', probability=np.float64(0.17724609375))]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_results = []\n",
    "for segments, _ in results_list:\n",
    "    segments = [i for i in segments]\n",
    "    segments_results.append(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50364,\n",
       " 2425,\n",
       " 11,\n",
       " 577,\n",
       " 366,\n",
       " 291,\n",
       " 884,\n",
       " 30,\n",
       " 1222,\n",
       " 1315,\n",
       " 307,\n",
       " 3780,\n",
       " 293,\n",
       " 220,\n",
       " 3322,\n",
       " 2146,\n",
       " 393,\n",
       " 2903,\n",
       " 293,\n",
       " 3191,\n",
       " 309,\n",
       " 13,\n",
       " 50614]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribed_bits[0][0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "stt_tokenizer = AutoTokenizer.from_pretrained(\"distil-whisper/distil-large-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|0.00|>',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'ula',\n",
       " 'and',\n",
       " '',\n",
       " 'the',\n",
       " 'guy',\n",
       " 'can',\n",
       " 'explain',\n",
       " 'and',\n",
       " 'fix',\n",
       " 'it',\n",
       " '.',\n",
       " '<|5.00|>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stt_tokenizer.convert_ids_to_tokens(transcribed_bits[0][0].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|0.00|>', 'Hello', ',', 'how', 'are', 'you', 'doing', '?', 'My', 'name', 'is', 'ula', 'and', '', 'the', 'guy', 'can', 'explain', 'and', 'fix', 'it', '.', '<|5.00|>'] <|0.00|> Hello, how are you doing? My name isula and the guy can explain and fix it.<|5.00|> ['<|0.00|>', 'Hello', ',', 'how', 'are', 'you', 'doing', '?', 'My', 'name', 'is', 'ula', 'and', '', 'the', 'guy', 'can', 'explain', 'and', 'fix', 'it', '.', '<|5.00|>']\n"
     ]
    }
   ],
   "source": [
    "tokens_from_ids = stt_tokenizer.convert_ids_to_tokens(transcribed_bits[0][0].tokens)\n",
    "string_from_toks = stt_tokenizer.convert_tokens_to_string(tokens_from_ids)\n",
    "string_to_toks = stt_tokenizer.tokenize(string_from_toks)\n",
    "print(tokens_from_ids, string_from_toks, string_to_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|0.00|>',\n",
       " 'Hello',\n",
       " ',',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'My',\n",
       " 'name',\n",
       " 'is',\n",
       " 'ula',\n",
       " 'and',\n",
       " '',\n",
       " 'the',\n",
       " 'guy',\n",
       " 'can',\n",
       " 'explain',\n",
       " 'and',\n",
       " 'fix',\n",
       " 'it',\n",
       " '.',\n",
       " '<|5.00|>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_from_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_match = all(a == b for a, b in zip(tokens_from_ids, string_to_toks)) and len(tokens_from_ids) == len(string_to_toks)\n",
    "all_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for segments in transcribed_bits:\n",
    "    segment_bits = []\n",
    "    for seg in segments:\n",
    "        print(seg)\n",
    "        segment_bits.append(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_prefix(str1, str2):\n",
    "    # Find the minimum length of the two strings\n",
    "    min_length = min(len(str1), len(str2))\n",
    "    \n",
    "    # Iterate through characters up to the minimum length\n",
    "    for i in range(min_length):\n",
    "        # If we find a mismatch, return the prefix up to this point\n",
    "        if str1[i] != str2[i]:\n",
    "            return str1[:i]\n",
    "    \n",
    "    # If we reached the end of the loop without finding a mismatch,\n",
    "    # the entire shorter string is a prefix of the longer one\n",
    "    return str1[:min_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " William Golding was born in Cornwall, England in 1911\n",
      " William Golding was born in Cornwall, England in 1911 and is a graduate of Oxford University. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m segments \u001b[38;5;129;01min\u001b[39;00m segments_results:\n\u001b[32m      4\u001b[39m     seg_text = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join([i.text \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m segments])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprevious_txt_seg\u001b[49m != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      6\u001b[39m         confirmed_txt_seg = longest_common_prefix(previous_txt_seg, seg_text)\n\u001b[32m      7\u001b[39m         final_text += confirmed_txt_seg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<stringsource>:69\u001b[39m, in \u001b[36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1470\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1512\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1313\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1950\u001b[39m, in \u001b[36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/small_utils/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2188\u001b[39m, in \u001b[36mPyDB.do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, exception_type)\u001b[39m\n\u001b[32m   2185\u001b[39m             from_this_thread.append(frame_custom_thread_id)\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads_suspended_single_notification.notify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[32m-> \u001b[39m\u001b[32m2188\u001b[39m         keep_suspended = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2190\u001b[39m frames_list = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[32m   2193\u001b[39m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repos/small_utils/.venv/lib/python3.12/site-packages/debugpy/_vendored/pydevd/pydevd.py:2257\u001b[39m, in \u001b[36mPyDB._do_wait_suspend\u001b[39m\u001b[34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[39m\n\u001b[32m   2254\u001b[39m                 queue.put(internal_cmd)\n\u001b[32m   2255\u001b[39m                 wait_timeout = TIMEOUT_FAST\n\u001b[32m-> \u001b[39m\u001b[32m2257\u001b[39m         \u001b[43mnotify_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2258\u001b[39m         notify_event.clear()\n\u001b[32m   2260\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "final_text = \"\"\n",
    "previous_txt_seg = \"\"\n",
    "for segments in segments_results:\n",
    "    seg_text = \" \".join([i.text for i in segments])\n",
    "    if previous_txt_seg != \"\":\n",
    "        confirmed_txt_seg = longest_common_prefix(previous_txt_seg, seg_text)\n",
    "        final_text += confirmed_txt_seg\n",
    "        previous_txt_seg = seg_text[len(confirmed_txt_seg):]\n",
    "    else:\n",
    "        previous_txt_seg = seg_text\n",
    "    print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'William Golding was born in Cornwall, England in 1911'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\"William Golding was born in Cornwall, England in 1911.\", \"William Golding was born in Cornwall, England in 1911 and is a graduate of Oxford University.  He states that he was brought up to\"]\n",
    "longest_common_prefix(texts[0], texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
